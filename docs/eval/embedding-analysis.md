# Embedding Analysis

This guide covers analyzing and interpreting embeddings generated by SimCLR models in the Phenoscape framework. Learn how to extract, visualize, and evaluate the quality of learned representations.

## Overview

Embedding analysis helps understand what features the model has learned and how well they capture biological patterns. This includes dimensionality reduction, clustering analysis, and correlation with biological metadata.

## Extracting Embeddings

### Basic Embedding Extraction

```python
import torch
import numpy as np
from pathlib import Path

def extract_embeddings(model, dataloader, device='cuda'):
    """Extract embeddings from trained SimCLR model."""
    model.eval()
    embeddings = []
    labels = []
    metadata = []
    
    with torch.no_grad():
        for batch in dataloader:
            images, batch_labels, batch_metadata = batch
            images = images.to(device)
            
            # Get embeddings (before projection head)
            features = model.encoder(images)
            embeddings.append(features.cpu().numpy())
            labels.extend(batch_labels)
            metadata.extend(batch_metadata)
    
    return np.vstack(embeddings), labels, metadata
```

### Multi-Modal Embedding Extraction

```python
def extract_multimodal_embeddings(model, rgb_loader, uv_loader, device='cuda'):
    """Extract embeddings from both RGB and UV modalities."""
    model.eval()
    rgb_embeddings = []
    uv_embeddings = []
    shared_ids = []
    
    with torch.no_grad():
        for (rgb_batch, uv_batch) in zip(rgb_loader, uv_loader):
            rgb_images, rgb_ids = rgb_batch
            uv_images, uv_ids = uv_batch
            
            # Ensure matching samples
            assert rgb_ids == uv_ids
            
            rgb_features = model.encoder(rgb_images.to(device))
            uv_features = model.encoder(uv_images.to(device))
            
            rgb_embeddings.append(rgb_features.cpu().numpy())
            uv_embeddings.append(uv_features.cpu().numpy())
            shared_ids.extend(rgb_ids)
    
    return {
        'rgb': np.vstack(rgb_embeddings),
        'uv': np.vstack(uv_embeddings),
        'ids': shared_ids
    }
```

## Dimensionality Reduction

### PCA Analysis

```python
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

def perform_pca_analysis(embeddings, n_components=50):
    """Perform PCA analysis on embeddings."""
    pca = PCA(n_components=n_components)
    reduced_embeddings = pca.fit_transform(embeddings)
    
    # Analyze explained variance
    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)
    
    # Plot variance explained
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), 
             pca.explained_variance_ratio_)
    plt.xlabel('Principal Component')
    plt.ylabel('Explained Variance Ratio')
    plt.title('Variance Explained by Each PC')
    
    plt.subplot(1, 2, 2)
    plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance)
    plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')
    plt.xlabel('Number of Components')
    plt.ylabel('Cumulative Explained Variance')
    plt.title('Cumulative Variance Explained')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig('pca_analysis.png', dpi=300)
    
    return reduced_embeddings, pca
```

### t-SNE Visualization

```python
from sklearn.manifold import TSNE

def create_tsne_visualization(embeddings, labels, perplexity=30):
    """Create t-SNE visualization of embeddings."""
    # Reduce dimensionality first if needed
    if embeddings.shape[1] > 50:
        pca = PCA(n_components=50)
        embeddings = pca.fit_transform(embeddings)
    
    # Apply t-SNE
    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)
    tsne_embeddings = tsne.fit_transform(embeddings)
    
    # Create visualization
    plt.figure(figsize=(12, 8))
    unique_labels = list(set(labels))
    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))
    
    for label, color in zip(unique_labels, colors):
        mask = np.array(labels) == label
        plt.scatter(tsne_embeddings[mask, 0], tsne_embeddings[mask, 1], 
                   c=[color], label=label, alpha=0.7)
    
    plt.xlabel('t-SNE 1')
    plt.ylabel('t-SNE 2')
    plt.title('t-SNE Visualization of Embeddings')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.savefig('tsne_visualization.png', dpi=300, bbox_inches='tight')
    
    return tsne_embeddings
```

### UMAP Visualization

```python
import umap

def create_umap_visualization(embeddings, labels, n_neighbors=15, min_dist=0.1):
    """Create UMAP visualization of embeddings."""
    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=42)
    umap_embeddings = reducer.fit_transform(embeddings)
    
    plt.figure(figsize=(12, 8))
    unique_labels = list(set(labels))
    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))
    
    for label, color in zip(unique_labels, colors):
        mask = np.array(labels) == label
        plt.scatter(umap_embeddings[mask, 0], umap_embeddings[mask, 1], 
                   c=[color], label=label, alpha=0.7)
    
    plt.xlabel('UMAP 1')
    plt.ylabel('UMAP 2')
    plt.title('UMAP Visualization of Embeddings')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.savefig('umap_visualization.png', dpi=300, bbox_inches='tight')
    
    return umap_embeddings
```

## Clustering Analysis

### K-Means Clustering

```python
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, adjusted_rand_score

def perform_kmeans_analysis(embeddings, labels, k_range=(2, 20)):
    """Perform K-means clustering analysis."""
    silhouette_scores = []
    inertias = []
    k_values = range(k_range[0], k_range[1] + 1)
    
    for k in k_values:
        kmeans = KMeans(n_clusters=k, random_state=42)
        cluster_labels = kmeans.fit_predict(embeddings)
        
        silhouette_avg = silhouette_score(embeddings, cluster_labels)
        silhouette_scores.append(silhouette_avg)
        inertias.append(kmeans.inertia_)
    
    # Plot results
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.plot(k_values, silhouette_scores, 'bo-')
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('Silhouette Score')
    plt.title('Silhouette Analysis')
    
    plt.subplot(1, 3, 2)
    plt.plot(k_values, inertias, 'ro-')
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('Inertia')
    plt.title('Elbow Method')
    
    # Best k based on silhouette score
    best_k = k_values[np.argmax(silhouette_scores)]
    kmeans_best = KMeans(n_clusters=best_k, random_state=42)
    best_clusters = kmeans_best.fit_predict(embeddings)
    
    # Compare with true labels if available
    if labels:
        ari_score = adjusted_rand_score(labels, best_clusters)
        plt.subplot(1, 3, 3)
        plt.text(0.1, 0.5, f'Best k: {best_k}\nARI Score: {ari_score:.3f}', 
                transform=plt.gca().transAxes, fontsize=12)
        plt.axis('off')
        plt.title('Clustering Results')
    
    plt.tight_layout()
    plt.savefig('clustering_analysis.png', dpi=300)
    
    return best_clusters, best_k
```

## Biological Correlation Analysis

### Species-Level Analysis

```python
def analyze_species_clustering(embeddings, species_labels):
    """Analyze how well embeddings cluster by species."""
    from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score
    
    # Perform clustering
    n_species = len(set(species_labels))
    kmeans = KMeans(n_clusters=n_species, random_state=42)
    cluster_labels = kmeans.fit_predict(embeddings)
    
    # Calculate clustering metrics
    homogeneity = homogeneity_score(species_labels, cluster_labels)
    completeness = completeness_score(species_labels, cluster_labels)
    v_measure = v_measure_score(species_labels, cluster_labels)
    
    results = {
        'homogeneity': homogeneity,
        'completeness': completeness,
        'v_measure': v_measure,
        'n_species': n_species
    }
    
    return results, cluster_labels
```

### Feature Correlation Analysis

```python
def correlate_with_biological_features(embeddings, metadata_df):
    """Correlate embedding dimensions with biological features."""
    from scipy.stats import pearsonr, spearmanr
    
    correlations = {}
    
    for feature in metadata_df.columns:
        if metadata_df[feature].dtype in ['int64', 'float64']:
            # Numerical features
            feature_correlations = []
            for dim in range(embeddings.shape[1]):
                corr, p_value = pearsonr(embeddings[:, dim], metadata_df[feature])
                feature_correlations.append({'correlation': corr, 'p_value': p_value})
            
            correlations[feature] = feature_correlations
    
    return correlations
```

## Cross-Modal Analysis

### RGB-UV Embedding Comparison

```python
def analyze_cross_modal_embeddings(rgb_embeddings, uv_embeddings, sample_ids):
    """Analyze relationships between RGB and UV embeddings."""
    from scipy.stats import pearsonr
    
    # Ensure matching samples
    assert len(rgb_embeddings) == len(uv_embeddings)
    
    # Calculate cross-modal similarities
    similarities = []
    for i in range(len(rgb_embeddings)):
        sim = np.dot(rgb_embeddings[i], uv_embeddings[i]) / (
            np.linalg.norm(rgb_embeddings[i]) * np.linalg.norm(uv_embeddings[i])
        )
        similarities.append(sim)
    
    # Dimension-wise correlations
    dim_correlations = []
    for dim in range(rgb_embeddings.shape[1]):
        corr, p_val = pearsonr(rgb_embeddings[:, dim], uv_embeddings[:, dim])
        dim_correlations.append({'dimension': dim, 'correlation': corr, 'p_value': p_val})
    
    # Visualization
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.hist(similarities, bins=50, alpha=0.7)
    plt.xlabel('Cosine Similarity')
    plt.ylabel('Frequency')
    plt.title('RGB-UV Embedding Similarities')
    
    plt.subplot(1, 3, 2)
    correlations = [d['correlation'] for d in dim_correlations]
    plt.plot(correlations)
    plt.xlabel('Embedding Dimension')
    plt.ylabel('Correlation')
    plt.title('Dimension-wise RGB-UV Correlations')
    
    plt.subplot(1, 3, 3)
    plt.scatter(rgb_embeddings[:, 0], uv_embeddings[:, 0], alpha=0.5)
    plt.xlabel('RGB Embedding (Dim 0)')
    plt.ylabel('UV Embedding (Dim 0)')
    plt.title('RGB vs UV (First Dimension)')
    
    plt.tight_layout()
    plt.savefig('cross_modal_analysis.png', dpi=300)
    
    return {
        'similarities': similarities,
        'dimension_correlations': dim_correlations,
        'mean_similarity': np.mean(similarities)
    }
```

## Quality Assessment

### Embedding Quality Metrics

```python
def assess_embedding_quality(embeddings, labels):
    """Assess the quality of learned embeddings."""
    from sklearn.neighbors import NearestNeighbors
    from sklearn.metrics import silhouette_score
    
    # Intra-class vs inter-class distances
    unique_labels = list(set(labels))
    intra_distances = []
    inter_distances = []
    
    for label in unique_labels:
        label_mask = np.array(labels) == label
        label_embeddings = embeddings[label_mask]
        
        if len(label_embeddings) > 1:
            # Intra-class distances
            for i in range(len(label_embeddings)):
                for j in range(i + 1, len(label_embeddings)):
                    dist = np.linalg.norm(label_embeddings[i] - label_embeddings[j])
                    intra_distances.append(dist)
        
        # Inter-class distances
        other_embeddings = embeddings[~label_mask]
        if len(other_embeddings) > 0:
            for emb in label_embeddings:
                distances = np.linalg.norm(other_embeddings - emb, axis=1)
                inter_distances.extend(distances.tolist())
    
    # Calculate metrics
    mean_intra = np.mean(intra_distances) if intra_distances else 0
    mean_inter = np.mean(inter_distances) if inter_distances else 0
    separation_ratio = mean_inter / mean_intra if mean_intra > 0 else float('inf')
    
    # Silhouette score
    silhouette = silhouette_score(embeddings, labels) if len(set(labels)) > 1 else 0
    
    return {
        'mean_intra_distance': mean_intra,
        'mean_inter_distance': mean_inter,
        'separation_ratio': separation_ratio,
        'silhouette_score': silhouette
    }
```

### Nearest Neighbor Analysis

```python
def analyze_nearest_neighbors(embeddings, labels, k=5):
    """Analyze nearest neighbor relationships in embedding space."""
    from sklearn.neighbors import NearestNeighbors
    
    nbrs = NearestNeighbors(n_neighbors=k+1, metric='cosine').fit(embeddings)
    distances, indices = nbrs.kneighbors(embeddings)
    
    # Calculate same-class neighbor ratios
    same_class_ratios = []
    for i, label in enumerate(labels):
        neighbor_labels = [labels[idx] for idx in indices[i][1:]]  # Exclude self
        same_class_count = sum(1 for nl in neighbor_labels if nl == label)
        same_class_ratios.append(same_class_count / k)
    
    return {
        'mean_same_class_ratio': np.mean(same_class_ratios),
        'std_same_class_ratio': np.std(same_class_ratios),
        'distances': distances,
        'indices': indices
    }
```

## Visualization Tools

### Interactive Embedding Explorer

```python
import plotly.express as px
import plotly.graph_objects as go

def create_interactive_embedding_plot(embeddings_2d, labels, metadata_df):
    """Create interactive embedding visualization."""
    df = metadata_df.copy()
    df['x'] = embeddings_2d[:, 0]
    df['y'] = embeddings_2d[:, 1]
    df['label'] = labels
    
    fig = px.scatter(
        df, x='x', y='y', color='label',
        hover_data=df.columns.tolist(),
        title='Interactive Embedding Visualization'
    )
    
    fig.update_layout(
        xaxis_title='Embedding Dimension 1',
        yaxis_title='Embedding Dimension 2',
        width=800,
        height=600
    )
    
    fig.write_html('interactive_embeddings.html')
    return fig
```

## Analysis Pipeline

### Complete Analysis Workflow

```python
def run_complete_embedding_analysis(model, dataloader, output_dir='embedding_analysis'):
    """Run complete embedding analysis pipeline."""
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # Extract embeddings
    print("Extracting embeddings...")
    embeddings, labels, metadata = extract_embeddings(model, dataloader)
    
    # PCA analysis
    print("Performing PCA analysis...")
    pca_embeddings, pca_model = perform_pca_analysis(embeddings)
    
    # Dimensionality reduction visualizations
    print("Creating visualizations...")
    tsne_embeddings = create_tsne_visualization(embeddings, labels)
    umap_embeddings = create_umap_visualization(embeddings, labels)
    
    # Clustering analysis
    print("Analyzing clusters...")
    clusters, best_k = perform_kmeans_analysis(embeddings, labels)
    
    # Quality assessment
    print("Assessing embedding quality...")
    quality_metrics = assess_embedding_quality(embeddings, labels)
    nn_analysis = analyze_nearest_neighbors(embeddings, labels)
    
    # Save results
    results = {
        'embeddings': embeddings,
        'labels': labels,
        'metadata': metadata,
        'pca_embeddings': pca_embeddings,
        'tsne_embeddings': tsne_embeddings,
        'umap_embeddings': umap_embeddings,
        'clusters': clusters,
        'best_k': best_k,
        'quality_metrics': quality_metrics,
        'nn_analysis': nn_analysis
    }
    
    # Save to file
    np.savez(output_dir / 'embedding_analysis_results.npz', **results)
    
    print(f"Analysis complete. Results saved to {output_dir}")
    return results
```

## Next Steps

- **[Visualization Tools](visualization.md)**: Advanced visualization techniques
- **[Statistical Metrics](statistical-metrics.md)**: Detailed statistical analysis
- **[Examples](../examples/)**: Practical analysis examples
